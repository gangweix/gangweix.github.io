<!doctype html>
<html>

<head>
<title>Gangwei Xu</title>

<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="keywords" content="Gangwei Xu, Huazhong University of Science and Technology"> 
<meta name="description" content="Gangwei's home page">
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-137722442-1', 'auto');
  ga('send', 'pageview');
</script>

</head>


<body>

<div id="layout-content" style="margin-top:25px">

<img src="./assets/img/homepage2.jpg" style="float:right; margin-top:30px; width: 20%;border-radius: 6px;" />
<table>
	<tbody>
		<tr>
			<td width="75%">
				<div id="toptitle">
					<h1>Gangwei Xu | 许刚伟 <h1>
				</div>

                <h3>Ph.D. Student</h3>

				<p>
                    Huazhong University of Science and Technology (HUST) </br>
				</p>
				<p >
					<a href="assets/resume_xgw.pdf">CV</a> &nbsp;/&nbsp;
					<a href="https://scholar.google.com/citations?user=ZVYrKpcAAAAJ&hl=zh-CN">Scholar</a> &nbsp;/&nbsp;
					<a href="https://github.com/gangweix">Github</a>
				  </p>
			</td>
		<tr>
	</tbody>
</table>

<h2>Short Bio</h2> 

<p>
	I am a second-year Ph.D. student at 
	<a href="https://www.hust.edu.cn/">Huazhong University of Science and Technology</a>, 
	supervised by <a href="https://scholar.google.com/citations?user=v6xQjnUAAAAJ&hl=zh-CN">Prof. Xin Yang</a>. 
	Prior to that, I earned a dual bachelor's degree in Communication Engineering and Financial Engineering from <a href="https://www.hust.edu.cn/">Huazhong University of Science and Technology</a>. 
	I also spent a wonderful time at <a href="https://www.shlab.org.cn/">Shanghai AI Laboratory</a> as a research intern, mentored by <a href="https://tianfan.info/">Prof. Tianfan Xue </a>. 
	Currently, I am a research intern at Xiaomi EV, focusing on generative world models.
</p>


<h2>Publications</h2>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<!-- <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:20px;width:20%;vertical-align:middle">
	  <div class="one">
		<div class="two" id='smerf_image'><video  width=100% muted autoplay loop>
		<source src="./assets/img/EMM.mp4" type="video/mp4" style="box-shadow: 2px 2px 2px 2px rgba(0, 0, 0, 0.4);object-fit: cover; border-radius: 10px;">
		Your browser does not support the video tag.
		</video></div>
		<img src='./assets/img/EMM.jpg' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
	  </div>
	  <script type="text/javascript">
		function smerf_start() {
		  document.getElementById('smerf_image').style.opacity = "1";
		}

		function smerf_stop() {
		  document.getElementById('smerf_image').style.opacity = "0";
		}
		smerf_stop()
	  </script>
	</td>
	<td style="padding:20px;width:80%;vertical-align:middle">
		<span class="papertitle">Event-Based Motion Magnification</span>
	  <br>
	  <strong>Yutian Chen</strong>,
	  <a href="https://scholar.google.com.hk/citations?user=5hsEmuQAAAAJ&hl=zh-CN">Shi Guo†</a>,
	  <a href="">Fangzheng Yu</a>,
	  <a href="">Feng Zhang</a>,
	  <a href="https://www.gujinwei.org/">Jinwei Gu</a>,
	  <a href="https://tianfan.info/">Tianfan Xue</a>
	  
	  <br>
	  European Conference on Computer Vision (ECCV), 2024.
	  <br>
	  <a href="https://openimaginglab.github.io/emm/">project page</a>
	  /
	  <a href="https://youtu.be/WmI7bv9nqjI">video</a>
	  /
	  <a href="https://arxiv.org/pdf/2402.11957.pdf">paper</a>
	  /
	  <a href="https://github.com/OpenImagingLab/emm">code</a>
	  <p></p>
	  <p>
		Detecting and magnifying imperceptible high-frequency motions in real-world scenarios with our RGB-event dual camera system.
	  </p>		
	</td>
  </tr> -->
<!--   <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:20px;width:20%;vertical-align:middle">
	  <div class="one">
		
		<img src='./assets/img/timelensxl.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
	  </div>
	</td>
	<td style="padding:20px;width:80%;vertical-align:middle">
		<span class="papertitle">TimeLens-XL: Real-time Event-based Video Frame Interpolation with Large Motion</span>
	  <br>
	  <a href="https://scholar.google.com/citations?user=JwQLEocAAAAJ&hl=en">Yongrui Ma</a>,	
	  <a href="https://scholar.google.com.hk/citations?user=5hsEmuQAAAAJ&hl=zh-CN">Shi Guo</a>,
	  <strong>Yutian Chen</strong>,
	  <a href="https://tianfan.info/">Tianfan Xue</a>,
	  <a href="https://www.gujinwei.org/">Jinwei Gu</a>
	  
	  
	  <br>
	  European Conference on Computer Vision (ECCV), 2024.
	  <br>
	  <a href="https://openimaginglab.github.io/TimeLens-XL/">project page</a>
	  /
	  <a href="https://youtu.be/HrfxliOQJSg?si=dzSd8CnfGmt9uGw7">video</a>
	  /
	  <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/11208.pdf">paper</a>
	  /
	  <a href="https://github.com/OpenImagingLab/TimeLens-XL">code</a>

	  <p></p>
	  <p>
		A real-time video frame interpolation method for large motion with a hybrid neuromorphic camera.
	  </p>		
	</td>
  </tr> -->

  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:20px;width:20%;vertical-align:middle">
	  <div class="one">
		
		<img src='./assets/img/banet_2d.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
	  </div>
	</td>
	<td style="padding:20px;width:80%;vertical-align:middle">
		<span class="papertitle">BANet: Bilateral Aggregation Network for Mobile Stereo Matching</span>
	  <br>
	 <strong>Gangwei Xu</strong>, Jiaxin Liu, Xianqi Wang, Junda Cheng, Yong Deng, Jinliang Zang, Yurui Chen, Xin Yang
	  <br>
	  ICCV 2025
	  <br>
	  <a href="https://arxiv.org/pdf/2503.03259">paper</a>
	  /
	  <a href="https://github.com/gangweix/BANet">code</a>

	  <p></p>
	  <p>
		A novel bilateral aggregation network for mobile stereo matching using only 2d convolutions.
	  </p>		
	</td>
  </tr>
	
  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:20px;width:20%;vertical-align:middle">
	  <div class="one">
		
		<img src='./assets/img/igev_pp.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
	  </div>
	</td>
	<td style="padding:20px;width:80%;vertical-align:middle">
		<span class="papertitle">IGEV++: Iterative Multi-range Geometry Encoding Volumes for Stereo Matching</span>
	  <br>
	 <strong>Gangwei Xu</strong>, Xianqi Wang, Zhaoxing Zhang, Junda Cheng, Chunyuan Liao, Xin Yang
	  <br>
	  TPAMI 2025
	  <br>
	  <a href="https://arxiv.org/pdf/2409.00638">paper</a>
	  /
	  <a href="https://github.com/gangweiX/IGEV-plusplus">code</a>

	  <p></p>
	  <p>
		An effective and efficient method for handling large disparities and extensive ill-posed regions.
	  </p>		
	</td>
  </tr>

  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:20px;width:20%;vertical-align:middle">
	  <div class="one">
		
		<img src='./assets/img/hdrflow.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
	  </div>
	</td>
	<td style="padding:20px;width:80%;vertical-align:middle">
		<span class="papertitle">HDRFlow: Real-Time HDR Video Reconstruction with Large Motions</span>
	  <br>
	 <strong>Gangwei Xu</strong>, Yujin Wang, Jinwei Gu, Tianfan Xue, Xin Yang
	  <br>
	  CVPR 2024
	  <br>
	  <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Xu_HDRFlow_Real-Time_HDR_Video_Reconstruction_with_Large_Motions_CVPR_2024_paper.pdf">paper</a>
	  /
	  <a href="https://github.com/OpenImagingLab/HDRFlow">code</a>

	  <p></p>
	  <p>
		A simple method for real-time HDR video reconstruction.
	  </p>		
	</td>
  </tr>

  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:20px;width:20%;vertical-align:middle">
	  <div class="one">
		
		<img src='./assets/img/selective_stereo.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
	  </div>
	</td>
	<td style="padding:20px;width:80%;vertical-align:middle">
		<span class="papertitle">Selective-Stereo: Adaptive Frequency Information Selection for Stereo Matching</span>
	  <br>
	 Xianqi Wang, <strong>Gangwei Xu</strong>, Hao Jia, Xin Yang
	  <br>
	  CVPR 2024 (Highlight)
	  <br>
	  <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Wang_Selective-Stereo_Adaptive_Frequency_Information_Selection_for_Stereo_Matching_CVPR_2024_paper.pdf">paper</a>
	  /
	  <a href="https://github.com/Windsrain/Selective-Stereo">code</a>

	  <p></p>
	  <p>
		A novel iterative update operator (SRU) for stereo matching.
	  </p>		
	</td>
  </tr>

  <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:20px;width:20%;vertical-align:middle">
	  <div class="one">
		
		<img src='./assets/img/fast_acv.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
	  </div>
	</td>
	<td style="padding:20px;width:80%;vertical-align:middle">
		<span class="papertitle">Accurate and Efficient Stereo Matching via Attention Concatenation Volume</span>
	  <br>
	 <strong>Gangwei Xu</strong>, Yun Wang, Junda Cheng, Jinhui Tang, Xin Yang
	  <br>
	  TPAMI 2024
	  <br>
	  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10330699">paper</a>
	  /
	  <a href="https://github.com/gangweiX/Fast-ACVNet">code</a>

	  <p></p>
	  <p>
		A novel cost volume representation (Fast-ACV) for real-time stereo matching.
	  </p>		
	</td>
  </tr>

 <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:20px;width:20%;vertical-align:middle">
	  <div class="one">
		
		<img src='./assets/img/igev.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
	  </div>
	</td>
	<td style="padding:20px;width:80%;vertical-align:middle">
		<span class="papertitle">Iterative Geometry Encoding Volume for Stereo Matching</span>
	  <br>
	 <strong>Gangwei Xu</strong>, Xianqi Wang, Xiaohuan Ding, Xin Yang
	  <br>
	  CVPR 2023
	  <br>
	  <a href="http://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Iterative_Geometry_Encoding_Volume_for_Stereo_Matching_CVPR_2023_paper.pdf">paper</a>
	  /
	  <a href="https://github.com/gangweiX/IGEV">code</a>

	  <p></p>
	  <p>
		A new deep network architecture that combines the complementary advantages of filtering-based and optimization-based methods.
	  </p>		
	</td>
  </tr>

 <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
	<td style="padding:20px;width:20%;vertical-align:middle">
	  <div class="one">
		
		<img src='./assets/img/acv.png' width=100% style="box-shadow: 1px 1px 2px 2px rgba(0, 0, 0, 0.4);border-radius: 10px;">
	  </div>
	</td>
	<td style="padding:20px;width:80%;vertical-align:middle">
		<span class="papertitle">Attention Concatenation Volume for Accurate and Efficient Stereo Matching</span>
	  <br>
	 <strong>Gangwei Xu</strong>, Junda Cheng, Peng Guo, Xin Yang
	  <br>
	  CVPR 2022
	  <br>
	  <a href="http://openaccess.thecvf.com/content/CVPR2022/papers/Xu_Attention_Concatenation_Volume_for_Accurate_and_Efficient_Stereo_Matching_CVPR_2022_paper.pdf">paper</a>
	  /
	  <a href="https://github.com/gangweiX/ACVNet">code</a>

	  <p></p>
	  <p>
		A novel cost volume representation (Attention Concatenation Volume) for stereo matching.
	  </p>		
	</td>
  </tr>

</tbody></table>

<h2>Honors</h2>
<p>
	HUST Academic Star (华中科技大学“学术新星”), 2024<br>
	National Scholarship (国家奖学金), PhD, 2024<br>
	National Scholarship (国家奖学金), master, 2023<br>
	First Prize, China Graduate AI Competition, 2023<br>
	Xiaomi Scholarship, 2022<br>
	
</p>	

<h2>Academic Services</h2>
<p>
<strong>Conference Reviewer: </strong> CVPR 2023, ICCV 2023, SIGGRAPH Asia 2023, CVPR 2024, ECCV 2024, ICRA 2024, ICLR 2025, AAAI 2025, CVPR 2025, ICCV 2025, NeurIPS 2025.
</p>	
<p>
<strong>Journal Reviewer: </strong> TPAMI, IJCV, TIP, RA-L.
</p>
</div>

</div>
</body>

</html>
